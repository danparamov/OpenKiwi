{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QE WMT20.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpbU30wtS0-J",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1NsDchauuyz",
        "colab_type": "code",
        "outputId": "253b3028-f437-4026-f28c-17791b423cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import utils\n",
        "import yaml\n",
        "from ipywidgets import interact, fixed, Textarea\n",
        "from functools import partial\n",
        "%load_ext yamlmagic"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The yamlmagic extension is already loaded. To reload it, use:\n",
            "  %reload_ext yamlmagic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clYbwtzSS-nF",
        "colab_type": "text"
      },
      "source": [
        "# Task 1: Sentence-Level Direct Assessment - WMT20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QFjTItzhqS1",
        "colab_type": "text"
      },
      "source": [
        "# Train Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjo9fOiFfbpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If using terminal, the following will download and extract the data\n",
        "# $ curl http://geolite.maxmind.com/download/geoip/database/GeoLite2-Country.tar.gz | tar -xz  -C /data/training/\n",
        "\n",
        "# Download Data\n",
        "OK_url = 'https://www.quest.dcs.shef.ac.uk/wmt20_files_qe/training_en-de.tar.gz'\n",
        "utils.download_kiwi(OK_url)\n",
        "\n",
        "# Extract Data\n",
        "import tarfile\n",
        "my_tar = tarfile.open('./data/training/training_en-de.tar.gz')\n",
        "my_tar.extractall('./data/training') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAnrsbcEHfmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduction of Data:\n",
        "\n",
        "# If using terminal, the following will get x amounts of rows\n",
        "# head -n 100 ./data/training/train.ende.en > tinytrainen\n",
        "\n",
        "import pandas as pd\n",
        "tinytrainen = pd.read_csv('./data/training/train.ende.en',chunksize=10000, sep='None, /n', engine='python')\n",
        "readme = tinytrainen.get_chunk(10000)\n",
        "readme.to_csv(r'./data/training/tinytrainen', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4xkpbPMjux2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tinytrainde = pd.read_csv('./data/training/train.ende.de',chunksize=10000, sep='None, /n', engine='python')\n",
        "reader = tinytrainde.get_chunk(10000)\n",
        "reader.to_csv(r'./data/training/tinytrainde', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXvQCd8UHRmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fccd0ca9-f1a8-417a-a251-eb1f891813d8"
      },
      "source": [
        "# Check tinytrain files size\n",
        "import os\n",
        "os.path.getsize('./data/training/tinytrainde')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1475606"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzN5eZsRUxC1",
        "colab_type": "code",
        "outputId": "36e4f590-72d5-4713-adbc-1db01edacd94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%yaml train_predictor\n",
        "#### Train Predictor  ####\n",
        "\n",
        "model: predictor\n",
        "\n",
        "# Model Files will be saved here\n",
        "output-dir: ./runs/predictor\n",
        "\n",
        "#### MODEL SPECIFIC OPTS ####\n",
        "\n",
        "## PREDICTOR ##\n",
        "\n",
        "# LSTM Settings (Both SRC and TGT)\n",
        "hidden-pred: 400\n",
        "rnn-layers-pred: 2\n",
        "# If set, takes precedence over other embedding params\n",
        "embedding-sizes: 200\n",
        "# Source, Target, and Target Softmax Embedding\n",
        "source-embeddings-size: 200\n",
        "target-embeddings-size: 200\n",
        "out-embeddings-size: 200\n",
        "# Dropout\n",
        "dropout-pred: 0.5\n",
        "# Set to true to predict from target to source\n",
        "# (To create a source predictor for source tag prediction)\n",
        "predict-inverse: false\n",
        "\n",
        "### TRAIN OPTS ###\n",
        "epochs: 6\n",
        "# Eval and checkpoint every n samples\n",
        "# Disable by setting to zero (default)\n",
        "checkpoint-validation-steps: 5000\n",
        "# If False, never save the Models\n",
        "checkpoint-save: true\n",
        "# Keep Only the n best models according to the main metric (Perplexity by default)\n",
        "# Ueful to avoid filling the harddrive during a long run\n",
        "checkpoint-keep-only-best: 1\n",
        "# If greater than zero, Early Stop after n evaluation cycles without improvement\n",
        "checkpoint-early-stop-patience: 0\n",
        "\n",
        "optimizer: adam\n",
        "# Print Train Stats Every n batches\n",
        "log-interval: 100\n",
        "# Learning Rate\n",
        "# 1e-3 * (batch_size / 32) seems to work well\n",
        "learning-rate: 2e-3\n",
        "learning-rate-decay: 0.6\n",
        "learning-rate-decay-start: 2\n",
        "train-batch-size: 64\n",
        "valid-batch-size: 64\n",
        "\n",
        "### DATA OPTS ###\n",
        "\n",
        "# Source and Target Files\n",
        "train-source: ./data/training/tinytrainen\n",
        "train-target: ./data/training/tinytrainde\n",
        "# Optionally load more data which is used only for vocabulary creation.\n",
        "# This is useful to reduce OOV words if the parallel data\n",
        "# and QE data are from different domains.\n",
        "# extend-source-vocab: data/WMT17/word_level/en_de/train.src\n",
        "# extend-target-vocab: data/WMT17/word_level/en_de/train.pe\n",
        "# Optionally Specify Validation Sets\n",
        "# valid-source: data/WMT17/word_level/en_de/dev.src\n",
        "# valid-target: data/WMT17/word_level/en_de/dev.pe\n",
        "# If No valid is specified, randomly split the train corpus\n",
        "split: 0.99\n",
        "\n",
        "\n",
        "## VOCAB ##\n",
        "\n",
        "# Load Vocabulary from a previous run.\n",
        "# This is needed e.g. for training a source predictor via the flag\n",
        "# predict-inverse: True\n",
        "# If set, the other vocab options are ignored.\n",
        "# load-vocab: /mnt/data/datasets/kiwi/trained_models/predest/en_de/vocab.torch\n",
        "\n",
        "source-vocab-size: 45000\n",
        "target-vocab-size: 45000\n",
        "# Remove Sentences not in the specified Length Range\n",
        "source-max-length: 50\n",
        "source-min-length: 1\n",
        "target-max-length: 50\n",
        "target-min-length: 1\n",
        "# Require Minimum Frequency of words\n",
        "source-vocab-min-frequency: 1\n",
        "target-vocab-min-frequency: 1\n",
        "\n",
        "\n",
        "### GENERAL OPTS ###\n",
        "\n",
        "# Experiment Name for MLFlow\n",
        "# experiment-name: EN-DE Pretrain Predictor\n",
        "# Do not set or set to negative number for CPU\n",
        "# gpu-id: 0"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            require(\n",
              "                [\n",
              "                    \"notebook/js/codecell\",\n",
              "                    \"codemirror/mode/yaml/yaml\"\n",
              "                ],\n",
              "                function(cc){\n",
              "                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n",
              "                        reg: [\"^%%yaml\"]\n",
              "                    }\n",
              "                }\n",
              "            );\n",
              "            "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0RY5AtFWCZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "utils.save_config(train_predictor, './runs/predictor/train_predictor.yaml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhpZeg3PWOtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kiwi\n",
        "\n",
        "predictor_config = './runs/predictor/train_predictor.yaml'\n",
        "kiwi.train(predictor_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6vINgWChAhq",
        "colab_type": "text"
      },
      "source": [
        "# Train Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3qSUer5uzpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#development file\n",
        "\n",
        "file = open('./data/traindev/dev.ende.df.short.tsv')\n",
        "data = file.readlines()[1:]\n",
        "file.close()\n",
        "\n",
        "de = open('./data/traindev/wmt20_dev.de', 'w')\n",
        "en = open('./data/traindev/wmt20_dev.en', 'w')\n",
        "hter = open('./data/traindev/wmt20_dev.hter_avg', 'w')\n",
        "for d in data:\n",
        "\td = d.split('\\t')\n",
        "\tprint(d)\n",
        "\tde.write(d[1] + \"\\n\")\n",
        "\ten.write(d[2] + \"\\n\")\n",
        "\thter.write(d[4] + \"\\n\")\n",
        "de.close()\n",
        "en.close()\n",
        "hter.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwO3XAo-vVE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train file\n",
        "\n",
        "file = open('./data/traindev/train.ende.df.short.tsv')\n",
        "data = file.readlines()[1:]\n",
        "file.close()\n",
        "\n",
        "\n",
        "de = open('./data/traindev/wmt20_train.de', 'w')\n",
        "en = open('./data/traindev/wmt20_train.en', 'w')\n",
        "hter = open('./data/traindev/wmt20_train.hter_avg', 'w')\n",
        "for d in data:\n",
        "\td = d.split('\\t')\n",
        "\tprint(d)\n",
        "\tde.write(d[1] + \"\\n\")\n",
        "\ten.write(d[2] + \"\\n\")\n",
        "\thter.write(d[4] + \"\\n\")\n",
        "de.close()\n",
        "en.close()\n",
        "hter.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEcaY5sAoRZB",
        "colab_type": "code",
        "outputId": "8eaa235d-9831-4cd8-8cd2-6b1bba53ab65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%yaml train_estimator\n",
        "### Train Predictor Estimator ###\n",
        "\n",
        "model: estimator\n",
        "\n",
        "# Model Files will be saved here\n",
        "output-dir: ./runs/estimator\n",
        "\n",
        "#### MODEL SPECIFIC OPTS ####\n",
        "\n",
        "## ESTIMATOR ##\n",
        "\n",
        "# If load-model points to a pretrained Estimator,\n",
        "# These settings are ignored.\n",
        "\n",
        "# LSTM Settings\n",
        "hidden-est: 125\n",
        "rnn-layers-est: 1\n",
        "dropout-est: 0.0\n",
        "# Use linear layer to reduce dimension prior to LSTM\n",
        "mlp-est: True\n",
        "\n",
        "# Multitask Learning Settings #\n",
        "\n",
        "# Continue training the predictor on the postedited text.\n",
        "# If set, will do an additional forward pass through the predictor\n",
        "# Using the SRC, PE pair and add the `Predictor` loss for the tokens in the\n",
        "# postedited text PE. Recommended if you have access to PE\n",
        "# Requires setting train-pe, valid-pe\n",
        "token-level: False\n",
        "# Predict Sentence Level Scores\n",
        "# Requires setting train-sentence-scores, valid-sentence-scores\n",
        "sentence-level: True\n",
        "# Use probabilistic Loss for sentence scores instead of squared error.\n",
        "# If set, the model will output mean and variance of a truncated Gaussian\n",
        "# distribution over the interval [0, 1], and use log-likelihood loss instead\n",
        "# of mean squared error.\n",
        "# Seems to improve performance\n",
        "sentence-ll: False\n",
        "# Predict Binary Label for each sentence, indicating hter == 0.0\n",
        "# Requires setting train-sentence-scores, valid-sentence-scores\n",
        "binary-level: False\n",
        "\n",
        "# WMT 20 Format Settings #\n",
        "\n",
        "# Predict target tags. Requires train-target-tags, valid-target-tags to be set.\n",
        "predict-target: false\n",
        "target-bad-weight: 2.5\n",
        "# Predict source tags. Requires train-source-tags, valid-source-tags to be set.\n",
        "predict-source: false\n",
        "source-bad-weight: 2.5\n",
        "# Predict gap tags. Requires train-target-tags, valid-target-tags to be set.\n",
        "# and wmt18-format set to true\n",
        "predict-gaps: false\n",
        "target-bad-weight: 2.5\n",
        "\n",
        "\n",
        "### TRAIN OPTS ###\n",
        "epochs: 10\n",
        "# Additionally Eval and checkpoint every n training steps\n",
        "# Explicitly disable by setting to zero (default)\n",
        "checkpoint-validation-steps: 0\n",
        "# If False, never save the Models\n",
        "checkpoint-save: true\n",
        "# Keep Only the n best models according to the main metric (F1Mult by default)\n",
        "# USeful to avoid filling the harddrive during a long run\n",
        "checkpoint-keep-only-best: 3\n",
        "# If greater than zero, Early Stop after n evaluation cycles without improvement\n",
        "checkpoint-early-stop-patience: 0\n",
        "\n",
        "\n",
        "# Print Train Stats Every n batches\n",
        "log-interval: 100\n",
        "# LR. Currently ADAM is only optimizer supported.\n",
        "# 1e-3 * (batch_size / 32) seems to work well\n",
        "learning-rate: 1e-3\n",
        "\n",
        "train-batch-size: 8\n",
        "valid-batch-size: 8\n",
        "\n",
        "\n",
        "\n",
        "### LOADING ###\n",
        "\n",
        "# Load pretrained (sub-)model.\n",
        "# If set, the model architecture params are ignored.\n",
        "# As the vocabulary of the pretrained model will be used,\n",
        "# all vocab-params will also be ignored.\n",
        "\n",
        "# (i) load-pred-source or load-pred-target: Predictor instance\n",
        "#     -> a new Estimator is initialized with the given predictor(s).\n",
        "# (ii) load-model: Estimator instance.\n",
        "#                  As the Predictor is a submodule of the Estimator,\n",
        "#                  load-pred-{source,target} will be ignored if this is set.\n",
        "\n",
        "# load-model: path_to_estimator\n",
        "# load-pred-source: path_to_predictor_source_target\n",
        "load-pred-target: ./runs/predictor/best_model.torch\n",
        "\n",
        "\n",
        "###  DATA ###\n",
        "\n",
        "# Set to True to use target_tags in WMT format\n",
        "wmt20-format: false\n",
        "\n",
        "train-source: ./data/traindev/wmt20_train.en\n",
        "train-target: ./data/traindev/wmt20_train.de\n",
        "# train-pe: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/data/train.pe\n",
        "# train-target-tags: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/data/train.tags\n",
        "train-sentence-scores: ./data/traindev/wmt20_train.hter_avg\n",
        "\n",
        "\n",
        "valid-source: ./data/traindev/wmt20_dev.en\n",
        "valid-target: ./data/traindev/wmt20_dev.de\n",
        "# valid-pe: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/WMT20/data/dev.pe\n",
        "# valid-target-tags: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/WMT20/data/dev.tags\n",
        "valid-sentence-scores: ./data/traindev/wmt20_dev.hter_avg\n",
        "\n",
        "### GENERAL OPTS ###\n",
        "\n",
        "# Experiment Name for MLFlow\n",
        "experiment-name: EN-DE Train Estimator\n",
        "# Do not set or set to negative number for CPU\n",
        "# gpu-id: 0"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            require(\n",
              "                [\n",
              "                    \"notebook/js/codecell\",\n",
              "                    \"codemirror/mode/yaml/yaml\"\n",
              "                ],\n",
              "                function(cc){\n",
              "                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n",
              "                        reg: [\"^%%yaml\"]\n",
              "                    }\n",
              "                }\n",
              "            );\n",
              "            "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFUuQVbFQyjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "utils.save_config(train_estimator, './runs/estimator/train_estimator.yaml')\n",
        "utils.save_config(train_estimator, './experiments/train_estimator.yaml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn_8wD9MvXd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kiwi\n",
        "\n",
        "estimator_config = './runs/estimator/train_estimator.yaml'\n",
        "kiwi.train(estimator_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj-MHatGzzHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}