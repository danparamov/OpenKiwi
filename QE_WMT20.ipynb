{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QE WMT20.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpbU30wtS0-J",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1NsDchauuyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import utils\n",
        "import yaml\n",
        "from ipywidgets import interact, fixed, Textarea\n",
        "from functools import partial\n",
        "%load_ext yamlmagic"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clYbwtzSS-nF",
        "colab_type": "text"
      },
      "source": [
        "# Task 1: Sentence-Level Direct Assessment - WMT20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QFjTItzhqS1",
        "colab_type": "text"
      },
      "source": [
        "# Train Predictor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjo9fOiFfbpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If using terminal, the following will download and extract the data\n",
        "# $ curl http://geolite.maxmind.com/download/geoip/database/GeoLite2-Country.tar.gz | tar -xz  -C /data/training/\n",
        "\n",
        "# Download and extract data\n",
        "OK_url = 'https://www.quest.dcs.shef.ac.uk/wmt20_files_qe/training_en-de.tar.gz'\n",
        "utils.download_kiwi(OK_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMR9oqdvi7Cu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tarfile\n",
        "my_tar = tarfile.open('./data/training/training_en-de.tar.gz')\n",
        "my_tar.extractall('./data/training') # specify which folder to extract to\n",
        "my_tar.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAnrsbcEHfmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reduction of Data:\n",
        "\n",
        "# If using terminal, the following will get x amounts of rows\n",
        "# head -n 100 ./data/training/train.ende.en > tinytrainen\n",
        "\n",
        "import pandas as pd\n",
        "tinytrainen = pd.read_csv('./data/training/train.ende.en',chunksize=2000000, sep='None, /n', engine='python')\n",
        "readme = tinytrainen.get_chunk(2000000)\n",
        "readme.to_csv(r'./data/training/tinytrainen', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4xkpbPMjux2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tinytrainde = pd.read_csv('./data/training/train.ende.de',chunksize=2000000, sep='None, /n', engine='python')\n",
        "reader = tinytrainde.get_chunk(2000000)\n",
        "reader.to_csv(r'./data/training/tinytrainde', index=False, header=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXvQCd8UHRmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48619973-0624-45ee-c085-e54de597e215"
      },
      "source": [
        "# Check tinytrain files size\n",
        "import os\n",
        "os.path.getsize('./data/training/tinytrainde')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "297527931"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzN5eZsRUxC1",
        "colab_type": "code",
        "outputId": "b87591f1-7779-4b2f-8d96-38975ec15c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%yaml train_predictor\n",
        "#### Train Predictor  ####\n",
        "\n",
        "model: predictor\n",
        "\n",
        "# Model Files will be saved here\n",
        "output-dir: ./OpenKiwi/runs/predictor\n",
        "\n",
        "#### MODEL SPECIFIC OPTS ####\n",
        "\n",
        "## PREDICTOR ##\n",
        "\n",
        "# LSTM Settings (Both SRC and TGT)\n",
        "hidden-pred: 400\n",
        "rnn-layers-pred: 2\n",
        "# If set, takes precedence over other embedding params\n",
        "embedding-sizes: 200\n",
        "# Source, Target, and Target Softmax Embedding\n",
        "source-embeddings-size: 200\n",
        "target-embeddings-size: 200\n",
        "out-embeddings-size: 200\n",
        "# Dropout\n",
        "dropout-pred: 0.5\n",
        "# Set to true to predict from target to source\n",
        "# (To create a source predictor for source tag prediction)\n",
        "predict-inverse: false\n",
        "\n",
        "### TRAIN OPTS ###\n",
        "epochs: 6\n",
        "# Eval and checkpoint every n samples\n",
        "# Disable by setting to zero (default)\n",
        "checkpoint-validation-steps: 5000\n",
        "# If False, never save the Models\n",
        "checkpoint-save: true\n",
        "# Keep Only the n best models according to the main metric (Perplexity by default)\n",
        "# Ueful to avoid filling the harddrive during a long run\n",
        "checkpoint-keep-only-best: 1\n",
        "# If greater than zero, Early Stop after n evaluation cycles without improvement\n",
        "checkpoint-early-stop-patience: 0\n",
        "\n",
        "optimizer: adam\n",
        "# Print Train Stats Every n batches\n",
        "log-interval: 100\n",
        "# Learning Rate\n",
        "# 1e-3 * (batch_size / 32) seems to work well\n",
        "learning-rate: 2e-3\n",
        "learning-rate-decay: 0.6\n",
        "learning-rate-decay-start: 2\n",
        "train-batch-size: 64\n",
        "valid-batch-size: 64\n",
        "\n",
        "### DATA OPTS ###\n",
        "\n",
        "# Source and Target Files\n",
        "train-source: ./OpenKiwi/data/training/tinytrainen\n",
        "train-target: ./OpenKiwi/data/training/tinytrainde\n",
        "# Optionally load more data which is used only for vocabulary creation.\n",
        "# This is useful to reduce OOV words if the parallel data\n",
        "# and QE data are from different domains.\n",
        "# extend-source-vocab: data/WMT17/word_level/en_de/train.src\n",
        "# extend-target-vocab: data/WMT17/word_level/en_de/train.pe\n",
        "# Optionally Specify Validation Sets\n",
        "# valid-source: data/WMT17/word_level/en_de/dev.src\n",
        "# valid-target: data/WMT17/word_level/en_de/dev.pe\n",
        "# If No valid is specified, randomly split the train corpus\n",
        "split: 0.99\n",
        "\n",
        "\n",
        "## VOCAB ##\n",
        "\n",
        "# Load Vocabulary from a previous run.\n",
        "# This is needed e.g. for training a source predictor via the flag\n",
        "# predict-inverse: True\n",
        "# If set, the other vocab options are ignored.\n",
        "# load-vocab: /mnt/data/datasets/kiwi/trained_models/predest/en_de/vocab.torch\n",
        "\n",
        "source-vocab-size: 45000\n",
        "target-vocab-size: 45000\n",
        "# Remove Sentences not in the specified Length Range\n",
        "source-max-length: 50\n",
        "source-min-length: 1\n",
        "target-max-length: 50\n",
        "target-min-length: 1\n",
        "# Require Minimum Frequency of words\n",
        "source-vocab-min-frequency: 1\n",
        "target-vocab-min-frequency: 1\n",
        "\n",
        "\n",
        "### GENERAL OPTS ###\n",
        "\n",
        "# Experiment Name for MLFlow\n",
        "# experiment-name: EN-DE Pretrain Predictor\n",
        "# Do not set or set to negative number for CPU\n",
        "# gpu-id: 0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            require(\n",
              "                [\n",
              "                    \"notebook/js/codecell\",\n",
              "                    \"codemirror/mode/yaml/yaml\"\n",
              "                ],\n",
              "                function(cc){\n",
              "                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n",
              "                        reg: [\"^%%yaml\"]\n",
              "                    }\n",
              "                }\n",
              "            );\n",
              "            "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0RY5AtFWCZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "utils.save_config(train_predictor, './OpenKiwi/runs/predictor/train_predictor.yaml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhpZeg3PWOtM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kiwi\n",
        "\n",
        "predictor_config = './OpenKiwi/runs/predictor/train_predictor.yaml'\n",
        "kiwi.train(predictor_config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6vINgWChAhq",
        "colab_type": "text"
      },
      "source": [
        "# Train Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3qSUer5uzpq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#development file\n",
        "\n",
        "file = open('./OpenKiwi/data/traindev/dev.ende.df.short.tsv')\n",
        "data = file.readlines()[1:]\n",
        "file.close()\n",
        "\n",
        "de = open('./OpenKiwi/data/traindev/wmt20_dev.de', 'w')\n",
        "en = open('./OpenKiwi/data/traindev/wmt20_dev.en', 'w')\n",
        "hter = open('./OpenKiwi/data/traindev/wmt20_dev.hter_avg', 'w')\n",
        "for d in data:\n",
        "\td = d.split('\\t')\n",
        "\tprint(d)\n",
        "\tde.write(d[1] + \"\\n\")\n",
        "\ten.write(d[2] + \"\\n\")\n",
        "\thter.write(d[4] + \"\\n\")\n",
        "de.close()\n",
        "en.close()\n",
        "hter.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwO3XAo-vVE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train file\n",
        "\n",
        "file = open('./OpenKiwi/data/traindev/train.ende.df.short.tsv')\n",
        "data = file.readlines()[1:]\n",
        "file.close()\n",
        "\n",
        "\n",
        "de = open('./OpenKiwi/data/traindev/wmt20_train.de', 'w')\n",
        "en = open('./OpenKiwi/data/traindev/wmt20_train.en', 'w')\n",
        "hter = open('./OpenKiwi/data/traindev/wmt20_train.hter_avg', 'w')\n",
        "for d in data:\n",
        "\td = d.split('\\t')\n",
        "\tprint(d)\n",
        "\tde.write(d[1] + \"\\n\")\n",
        "\ten.write(d[2] + \"\\n\")\n",
        "\thter.write(d[4] + \"\\n\")\n",
        "de.close()\n",
        "en.close()\n",
        "hter.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEcaY5sAoRZB",
        "colab_type": "code",
        "outputId": "8dd9eb63-41c0-42ee-efe3-a15453e148d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%yaml train_estimator\n",
        "### Train Predictor Estimator ###\n",
        "\n",
        "model: estimator\n",
        "\n",
        "# Model Files will be saved here\n",
        "output-dir: /OpenKiwi/runs/estimator\n",
        "\n",
        "#### MODEL SPECIFIC OPTS ####\n",
        "\n",
        "## ESTIMATOR ##\n",
        "\n",
        "# If load-model points to a pretrained Estimator,\n",
        "# These settings are ignored.\n",
        "\n",
        "# LSTM Settings\n",
        "hidden-est: 125\n",
        "rnn-layers-est: 1\n",
        "dropout-est: 0.0\n",
        "# Use linear layer to reduce dimension prior to LSTM\n",
        "mlp-est: True\n",
        "\n",
        "# Multitask Learning Settings #\n",
        "\n",
        "# Continue training the predictor on the postedited text.\n",
        "# If set, will do an additional forward pass through the predictor\n",
        "# Using the SRC, PE pair and add the `Predictor` loss for the tokens in the\n",
        "# postedited text PE. Recommended if you have access to PE\n",
        "# Requires setting train-pe, valid-pe\n",
        "token-level: False\n",
        "# Predict Sentence Level Scores\n",
        "# Requires setting train-sentence-scores, valid-sentence-scores\n",
        "sentence-level: True\n",
        "# Use probabilistic Loss for sentence scores instead of squared error.\n",
        "# If set, the model will output mean and variance of a truncated Gaussian\n",
        "# distribution over the interval [0, 1], and use log-likelihood loss instead\n",
        "# of mean squared error.\n",
        "# Seems to improve performance\n",
        "sentence-ll: False\n",
        "# Predict Binary Label for each sentence, indicating hter == 0.0\n",
        "# Requires setting train-sentence-scores, valid-sentence-scores\n",
        "binary-level: False\n",
        "\n",
        "# WMT 20 Format Settings #\n",
        "\n",
        "# Predict target tags. Requires train-target-tags, valid-target-tags to be set.\n",
        "predict-target: false\n",
        "target-bad-weight: 2.5\n",
        "# Predict source tags. Requires train-source-tags, valid-source-tags to be set.\n",
        "predict-source: false\n",
        "source-bad-weight: 2.5\n",
        "# Predict gap tags. Requires train-target-tags, valid-target-tags to be set.\n",
        "# and wmt18-format set to true\n",
        "predict-gaps: false\n",
        "target-bad-weight: 2.5\n",
        "\n",
        "\n",
        "### TRAIN OPTS ###\n",
        "epochs: 10\n",
        "# Additionally Eval and checkpoint every n training steps\n",
        "# Explicitly disable by setting to zero (default)\n",
        "checkpoint-validation-steps: 0\n",
        "# If False, never save the Models\n",
        "checkpoint-save: true\n",
        "# Keep Only the n best models according to the main metric (F1Mult by default)\n",
        "# USeful to avoid filling the harddrive during a long run\n",
        "checkpoint-keep-only-best: 3\n",
        "# If greater than zero, Early Stop after n evaluation cycles without improvement\n",
        "checkpoint-early-stop-patience: 0\n",
        "\n",
        "\n",
        "# Print Train Stats Every n batches\n",
        "log-interval: 100\n",
        "# LR. Currently ADAM is only optimizer supported.\n",
        "# 1e-3 * (batch_size / 32) seems to work well\n",
        "learning-rate: 1e-3\n",
        "\n",
        "train-batch-size: 8\n",
        "valid-batch-size: 8\n",
        "\n",
        "\n",
        "\n",
        "### LOADING ###\n",
        "\n",
        "# Load pretrained (sub-)model.\n",
        "# If set, the model architecture params are ignored.\n",
        "# As the vocabulary of the pretrained model will be used,\n",
        "# all vocab-params will also be ignored.\n",
        "\n",
        "# (i) load-pred-source or load-pred-target: Predictor instance\n",
        "#     -> a new Estimator is initialized with the given predictor(s).\n",
        "# (ii) load-model: Estimator instance.\n",
        "#                  As the Predictor is a submodule of the Estimator,\n",
        "#                  load-pred-{source,target} will be ignored if this is set.\n",
        "\n",
        "# load-model: path_to_estimator\n",
        "# load-pred-source: path_to_predictor_source_target\n",
        "load-pred-target: ./OpenKiwi/runs/predictor/best_model.torch\n",
        "\n",
        "\n",
        "###  DATA ###\n",
        "\n",
        "# Set to True to use target_tags in WMT format\n",
        "wmt20-format: false\n",
        "\n",
        "train-source: ./OpenKiwi/data/traindev/wmt20_train.en\n",
        "train-target: ./OpenKiwi/data/traindev/wmt20_train.de\n",
        "# train-pe: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/data/train.pe\n",
        "# train-target-tags: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/data/train.tags\n",
        "train-sentence-scores: ./OpenKiwi/data/traindev/wmt20_train.hter_avg\n",
        "\n",
        "\n",
        "valid-source: ./OpenKiwi/data/traindev/wmt20_dev.en\n",
        "valid-target: ./OpenKiwi/data/traindev/wmt20_dev.de\n",
        "# valid-pe: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/WMT20/data/dev.pe\n",
        "# valid-target-tags: /content/drive/My Drive/Proyectos/Machine Learning/Colab Notebooks/WMT20/data/dev.tags\n",
        "valid-sentence-scores: ./OpenKiwi/data/traindev/wmt20_dev.hter_avg\n",
        "\n",
        "### GENERAL OPTS ###\n",
        "\n",
        "# Experiment Name for MLFlow\n",
        "experiment-name: EN-DE Train Estimator\n",
        "# Do not set or set to negative number for CPU\n",
        "# gpu-id: 0"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            require(\n",
              "                [\n",
              "                    \"notebook/js/codecell\",\n",
              "                    \"codemirror/mode/yaml/yaml\"\n",
              "                ],\n",
              "                function(cc){\n",
              "                    cc.CodeCell.options_default.highlight_modes.magic_yaml = {\n",
              "                        reg: [\"^%%yaml\"]\n",
              "                    }\n",
              "                }\n",
              "            );\n",
              "            "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFUuQVbFQyjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "utils.save_config(train_estimator, './OpenKiwi/runs/estimator/train_estimator.yml')\n",
        "utils.save_config(train_estimator, './OpenKiwi/experiments/train_estimator.yml')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn_8wD9MvXd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c47c0950-5c1e-49cc-c5ee-cc7608ec1730"
      },
      "source": [
        "import kiwi\n",
        "\n",
        "estimator_config = './OpenKiwi/runs/estimator/train_estimator.yml'\n",
        "kiwi.train(estimator_config)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:29:04.479 [root setup:380] This is run ID: 358737f214564365ac497d5d40aaeaa8\n",
            "2020-05-22 02:29:04.479 [root setup:383] Inside experiment ID: 0 (EN-DE Train Estimator)\n",
            "2020-05-22 02:29:04.480 [root setup:386] Local output directory is: runs/estimator\n",
            "2020-05-22 02:29:04.481 [root setup:389] Logging execution to MLflow at: None\n",
            "2020-05-22 02:29:04.482 [root setup:397] Using CPU\n",
            "2020-05-22 02:29:04.482 [root setup:400] Artifacts location: None\n",
            "2020-05-22 02:29:04.490 [kiwi.lib.train run:154] Training the PredEst (Predictor-Estimator) model\n",
            "2020-05-22 02:29:06.056 [kiwi.data.utils load_vocabularies_to_fields:126] Loaded vocabularies from runs/predictor/best_model.torch\n",
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "2020-05-22 02:29:07.059 [kiwi.lib.train run:187] Estimator(\n",
            "  (predictor_tgt): Predictor(\n",
            "    (attention): Attention(\n",
            "      (scorer): MLPScorer(\n",
            "        (layers): ModuleList(\n",
            "          (0): Sequential(\n",
            "            (0): Linear(in_features=1600, out_features=800, bias=True)\n",
            "            (1): Tanh()\n",
            "          )\n",
            "          (1): Sequential(\n",
            "            (0): Linear(in_features=800, out_features=1, bias=True)\n",
            "            (1): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embedding_source): Embedding(19379, 200, padding_idx=1)\n",
            "    (embedding_target): Embedding(27694, 200, padding_idx=1)\n",
            "    (lstm_source): LSTM(200, 400, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "    (forward_target): LSTM(200, 400, num_layers=2, batch_first=True, dropout=0.5)\n",
            "    (backward_target): LSTM(200, 400, num_layers=2, batch_first=True, dropout=0.5)\n",
            "    (W1): Embedding(27694, 200, padding_idx=1)\n",
            "    (_loss): CrossEntropyLoss()\n",
            "  )\n",
            "  (mlp): Sequential(\n",
            "    (0): Linear(in_features=1000, out_features=128, bias=True)\n",
            "    (1): Tanh()\n",
            "  )\n",
            "  (lstm): LSTM(128, 128, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (embedding_out): Linear(in_features=256, out_features=2, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (sentence_pred): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (1): Sigmoid()\n",
            "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (3): Sigmoid()\n",
            "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
            "  )\n",
            "  (xents): ModuleDict(\n",
            "    (tags): CrossEntropyLoss()\n",
            "  )\n",
            "  (mse_loss): MSELoss()\n",
            ")\n",
            "2020-05-22 02:29:07.060 [kiwi.lib.train run:188] 27774652 parameters\n",
            "2020-05-22 02:29:07.061 [kiwi.trainers.trainer run:75] Epoch 1 of 3\n",
            "Batches:  90%|████████████████████████▎  | 99/110 [02:39<00:18,  1.72s/ batches]2020-05-22 02:31:49.307 [kiwi.metrics.stats log:60] RMSE: 81.1973, PEARSON: -0.0097, SPEARMAN: -0.0309, UNKS: 0.5404\n",
            "Batches:  91%|███████████████████████▋  | 100/110 [02:42<00:18,  1.88s/ batches]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████████████████████| 110/110 [02:58<00:00,  1.62s/ batches]\n",
            "2020-05-22 02:32:05.086 [kiwi.metrics.stats log:60] RMSE: 76.8967, PEARSON: 0.0132, SPEARMAN: 0.0000, UNKS: 0.5449\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/scipy/stats/stats.py:3399: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n",
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n",
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in greater\n",
            "  return (a < x) & (x < b)\n",
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:901: RuntimeWarning: invalid value encountered in less\n",
            "  return (a < x) & (x < b)\n",
            "/home/daniel_paramo_v_gmail_com/.local/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py:1892: RuntimeWarning: invalid value encountered in less_equal\n",
            "  cond2 = cond0 & (x <= _a)\n",
            "2020-05-22 02:32:17.862 [kiwi.metrics.stats log:60] EVAL_RMSE: 71.7530, EVAL_PEARSON: nan, EVAL_SPEARMAN: nan, EVAL_UNKS: 0.5383\n",
            "2020-05-22 02:32:17.863 [root save:183] Saving training state to runs/estimator/epoch_1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:32:18.320 [root save_latest:241] Saving training state to runs/estimator/temp_latest_epoch\n",
            "2020-05-22 02:32:18.322 [kiwi.trainers.callbacks save_latest:252] Moving runs/estimator/temp_latest_epoch to runs/estimator/latest_epoch\n",
            "2020-05-22 02:32:30.878 [kiwi.data.utils save_predicted_probabilities:265] Saving sentence_scores predictions to runs/estimator/epoch_1/sentence_scores\n",
            "2020-05-22 02:32:30.880 [kiwi.trainers.trainer run:75] Epoch 2 of 3\n",
            "Batches:  81%|█████████████████████▊     | 89/110 [02:26<00:29,  1.43s/ batches]2020-05-22 02:34:58.805 [kiwi.metrics.stats log:60] RMSE: 72.8000, PEARSON: -0.0020, SPEARMAN: -0.0159, UNKS: 0.5424\n",
            "Batches:  82%|██████████████████████     | 90/110 [02:27<00:28,  1.42s/ batches]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████████████████████| 110/110 [03:01<00:00,  1.65s/ batches]\n",
            "2020-05-22 02:35:31.978 [kiwi.metrics.stats log:60] RMSE: 68.8780, PEARSON: 0.0272, SPEARMAN: 0.0122, UNKS: 0.5332\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:35:45.000 [kiwi.metrics.stats log:60] EVAL_RMSE: 63.3713, EVAL_PEARSON: nan, EVAL_SPEARMAN: nan, EVAL_UNKS: 0.5383\n",
            "2020-05-22 02:35:45.002 [root save:183] Saving training state to runs/estimator/epoch_2\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:35:45.454 [root save_latest:241] Saving training state to runs/estimator/temp_latest_epoch\n",
            "2020-05-22 02:35:45.456 [kiwi.trainers.callbacks _remove_snapshot:178] Removing previous snapshot: runs/estimator/latest_epoch\n",
            "2020-05-22 02:35:45.457 [kiwi.trainers.callbacks save_latest:252] Moving runs/estimator/temp_latest_epoch to runs/estimator/latest_epoch\n",
            "2020-05-22 02:35:58.407 [kiwi.data.utils save_predicted_probabilities:265] Saving sentence_scores predictions to runs/estimator/epoch_2/sentence_scores\n",
            "2020-05-22 02:35:58.410 [kiwi.trainers.trainer run:75] Epoch 3 of 3\n",
            "Batches:  72%|███████████████████▍       | 79/110 [02:10<00:54,  1.76s/ batches]2020-05-22 02:38:11.466 [kiwi.metrics.stats log:60] RMSE: 64.8512, PEARSON: 0.0007, SPEARMAN: 0.0062, UNKS: 0.5402\n",
            "Batches:  73%|███████████████████▋       | 80/110 [02:13<01:00,  2.01s/ batches]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████████████████████| 110/110 [03:01<00:00,  1.65s/ batches]\n",
            "2020-05-22 02:38:59.906 [kiwi.metrics.stats log:60] RMSE: 61.2775, PEARSON: -0.0062, SPEARMAN: -0.0063, UNKS: 0.5423\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:39:13.076 [kiwi.metrics.stats log:60] EVAL_RMSE: 55.6197, EVAL_PEARSON: nan, EVAL_SPEARMAN: nan, EVAL_UNKS: 0.5383\n",
            "2020-05-22 02:39:13.078 [root save:183] Saving training state to runs/estimator/epoch_3\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-05-22 02:39:13.529 [root save_latest:241] Saving training state to runs/estimator/temp_latest_epoch\n",
            "2020-05-22 02:39:13.531 [kiwi.trainers.callbacks _remove_snapshot:178] Removing previous snapshot: runs/estimator/latest_epoch\n",
            "2020-05-22 02:39:13.532 [kiwi.trainers.callbacks save_latest:252] Moving runs/estimator/temp_latest_epoch to runs/estimator/latest_epoch\n",
            "2020-05-22 02:39:26.452 [kiwi.data.utils save_predicted_probabilities:265] Saving sentence_scores predictions to runs/estimator/epoch_3/sentence_scores\n",
            "2020-05-22 02:39:26.455 [root copy_best_model:266] Copying best model to runs/estimator/best_model.torch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<kiwi.lib.train.TrainRunInfo at 0x7fdcaf0da990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj-MHatGzzHN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}